{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 489 files belonging to 2 classes.\n",
      "Found 121 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "img_height, img_width = 64, 64\n",
    "batch_size = 16\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"dataset/resized_images/train\",\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"dataset/resized_images/test\",\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "    #  tf.keras.layers.Rescaling(1./255),\n",
    "     tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "     tf.keras.layers.MaxPooling2D(),\n",
    "     tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "     tf.keras.layers.MaxPooling2D(),\n",
    "     tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "     tf.keras.layers.MaxPooling2D(),\n",
    "     tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "     tf.keras.layers.MaxPooling2D(),\n",
    "     tf.keras.layers.Flatten(),\n",
    "     tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "     tf.keras.layers.Dense(2)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from PIL import Image\n",
    "\n",
    "# path = \"dataset\"\n",
    "\n",
    "# # Create a new directory for resized images\n",
    "# new_path = os.path.join(path, \"resized_images\")\n",
    "# if not os.path.exists(new_path):\n",
    "#     os.makedirs(new_path)\n",
    "\n",
    "# # Iterate through all subdirectories (each representing a category)\n",
    "# for subdir, dirs, files in os.walk(os.path.join(path, \"test\")):\n",
    "#     # Get the category name from the subdirectory name\n",
    "#     category_name = os.path.basename(subdir)\n",
    "\n",
    "#     # Create a subdirectory for the current category in the new directory\n",
    "#     category_path = os.path.join(new_path, category_name)\n",
    "#     if not os.path.exists(category_path):\n",
    "#         os.makedirs(category_path)\n",
    "\n",
    "#     for file in files:\n",
    "#         # Open the image\n",
    "#         img = Image.open(os.path.join(subdir, file))\n",
    "#         img = img.convert('RGB')\n",
    "#         # Resize the image\n",
    "#         img_resized = img\n",
    "#         file = file.split('.')[0]+'.png'\n",
    "#         # Save the resized image in the new directory\n",
    "#         new_file_path = os.path.join(category_path, file)\n",
    "#         print(new_file_path)\n",
    "#         img_resized.save(new_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31/31 [==============================] - 4s 125ms/step - loss: 0.1154 - accuracy: 0.9509 - val_loss: 0.2828 - val_accuracy: 0.9256\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 5s 130ms/step - loss: 0.1009 - accuracy: 0.9652 - val_loss: 0.2455 - val_accuracy: 0.9256\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 5s 129ms/step - loss: 0.0448 - accuracy: 0.9898 - val_loss: 0.3201 - val_accuracy: 0.9091\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.0498 - accuracy: 0.9796 - val_loss: 0.3252 - val_accuracy: 0.9339\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 4s 125ms/step - loss: 0.0857 - accuracy: 0.9775 - val_loss: 0.3650 - val_accuracy: 0.9174\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 0.1080 - accuracy: 0.9550 - val_loss: 0.4061 - val_accuracy: 0.8926\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 0.0931 - accuracy: 0.9734 - val_loss: 0.3060 - val_accuracy: 0.9174\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 0.0705 - accuracy: 0.9755 - val_loss: 0.3722 - val_accuracy: 0.9008\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 0.0479 - accuracy: 0.9918 - val_loss: 0.2475 - val_accuracy: 0.9339\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 0.0465 - accuracy: 0.9877 - val_loss: 0.3581 - val_accuracy: 0.9174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21d74b53460>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data = test_ds,\n",
    "    epochs = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# tflite_model = converter.convert()\n",
    "\n",
    "# with open(\"model.tflite\", 'wb') as f:\n",
    "#   f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
