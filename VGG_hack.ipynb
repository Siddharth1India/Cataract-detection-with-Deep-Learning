{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0+cu117'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "batch_size = 1\n",
    "img_size = 224\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.Resize(size=(64,64)),\n",
    "    transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    # transforms.Resize(230),\n",
    "    transforms.Resize(size=(64,64)),\n",
    "    # transforms.CenterCrop(img_size),\n",
    "    # transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_set = datasets.ImageFolder(\"./dataset/train\", transform=train_transform)\n",
    "trainloader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = datasets.ImageFolder(\"./dataset/test\", transform=test_transform)\n",
    "testloader = DataLoader(test_set, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature, target = next(iter(trainloader))\n",
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG11_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "device = 'cuda'\n",
    "model = torchvision.models.vgg11(pretrained=True).to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier._modules['6'] = nn.Linear(4096, 2)\n",
    "model.to(device=device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() # this is also called \"criterion\"/\"cost function\" in some places\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            running_loss = 0.\n",
    "    # scheduler.step()\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    classes = torch.argmax(predictions, dim=1)\n",
    "    return torch.mean((classes == labels).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "LOSS train 0.0 test 0.45014050602912903 accuracy 0.8181818127632141\n",
      "EPOCH 2:\n",
      "LOSS train 0.0 test 0.4260518252849579 accuracy 0.8429751992225647\n",
      "EPOCH 3:\n",
      "LOSS train 0.0 test 0.4090137779712677 accuracy 0.8429751992225647\n",
      "EPOCH 4:\n",
      "LOSS train 0.0 test 0.39822277426719666 accuracy 0.8512396216392517\n",
      "EPOCH 5:\n",
      "LOSS train 0.0 test 0.38907212018966675 accuracy 0.8347107172012329\n",
      "EPOCH 6:\n",
      "LOSS train 0.0 test 0.37823721766471863 accuracy 0.8429751992225647\n",
      "EPOCH 7:\n",
      "LOSS train 0.0 test 0.3720003366470337 accuracy 0.8347107172012329\n",
      "EPOCH 8:\n",
      "LOSS train 0.0 test 0.36572331190109253 accuracy 0.8347107172012329\n",
      "EPOCH 9:\n",
      "LOSS train 0.0 test 0.3605444133281708 accuracy 0.8429751992225647\n",
      "EPOCH 10:\n",
      "LOSS train 0.0 test 0.35700294375419617 accuracy 0.8512396216392517\n",
      "EPOCH 11:\n",
      "LOSS train 0.0 test 0.35539641976356506 accuracy 0.8595041036605835\n",
      "EPOCH 12:\n",
      "LOSS train 0.0 test 0.3518645167350769 accuracy 0.8677685856819153\n",
      "EPOCH 13:\n",
      "LOSS train 0.0 test 0.3518843352794647 accuracy 0.8595041036605835\n",
      "EPOCH 14:\n",
      "LOSS train 0.0 test 0.35078123211860657 accuracy 0.8595041036605835\n",
      "EPOCH 15:\n",
      "LOSS train 0.0 test 0.3521139323711395 accuracy 0.8595041036605835\n",
      "EPOCH 16:\n",
      "LOSS train 0.0 test 0.3548533022403717 accuracy 0.8429751992225647\n",
      "EPOCH 17:\n",
      "LOSS train 0.0 test 0.35324159264564514 accuracy 0.8347107172012329\n",
      "EPOCH 18:\n",
      "LOSS train 0.0 test 0.35906773805618286 accuracy 0.8347107172012329\n",
      "EPOCH 19:\n",
      "LOSS train 0.0 test 0.3580842912197113 accuracy 0.8429751992225647\n",
      "EPOCH 20:\n",
      "LOSS train 0.0 test 0.35694634914398193 accuracy 0.8347107172012329\n"
     ]
    }
   ],
   "source": [
    "epoch_number = 0\n",
    "from datetime import datetime\n",
    "# torch.cuda.manual_seed(42)\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "best_vloss = 1_000_000.\n",
    "data_for_acc  =[]\n",
    "EPOCHS = 20\n",
    "for epoch in range(EPOCHS):\n",
    "    running_accuracy = 0.00\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number)\n",
    "\n",
    "    # We don't need gradients on to do reporting\n",
    "    model.train(False)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    for i, vdata in enumerate(testloader):\n",
    "        vinputs, vlabels = vdata\n",
    "        vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n",
    "        voutputs = model(vinputs)\n",
    "        vloss = loss_fn(voutputs, vlabels)\n",
    "        running_accuracy += accuracy(voutputs, vlabels)\n",
    "        running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    running_accuracy /= len(testloader)\n",
    "    print('LOSS train {} test {} accuracy {}'.format(avg_loss, avg_vloss, running_accuracy))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "  \n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'VGG.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
